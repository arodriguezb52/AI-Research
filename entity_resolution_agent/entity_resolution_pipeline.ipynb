{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "➜ Before cleaning — Abt sample:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>description</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>552</td>\n",
       "      <td>Sony Turntable - PSLX350H</td>\n",
       "      <td>Sony Turntable - PSLX350H/ Belt Drive System/ ...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>580</td>\n",
       "      <td>Bose Acoustimass 5 Series III Speaker System -...</td>\n",
       "      <td>Bose Acoustimass 5 Series III Speaker System -...</td>\n",
       "      <td>$399.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4696</td>\n",
       "      <td>Sony Switcher - SBV40S</td>\n",
       "      <td>Sony Switcher - SBV40S/ Eliminates Disconnecti...</td>\n",
       "      <td>$49.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id                                               name  \\\n",
       "0   552                          Sony Turntable - PSLX350H   \n",
       "1   580  Bose Acoustimass 5 Series III Speaker System -...   \n",
       "2  4696                             Sony Switcher - SBV40S   \n",
       "\n",
       "                                         description    price  \n",
       "0  Sony Turntable - PSLX350H/ Belt Drive System/ ...      NaN  \n",
       "1  Bose Acoustimass 5 Series III Speaker System -...  $399.00  \n",
       "2  Sony Switcher - SBV40S/ Eliminates Disconnecti...   $49.00  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "➜ Before cleaning — Buy sample:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>description</th>\n",
       "      <th>manufacturer</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10011646</td>\n",
       "      <td>Linksys EtherFast EZXS88W Ethernet Switch - EZ...</td>\n",
       "      <td>Linksys EtherFast 8-Port 10/100 Switch (New/Wo...</td>\n",
       "      <td>LINKSYS</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10140760</td>\n",
       "      <td>Linksys EtherFast EZXS55W Ethernet Switch</td>\n",
       "      <td>5 x 10/100Base-TX LAN</td>\n",
       "      <td>LINKSYS</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10221960</td>\n",
       "      <td>Netgear ProSafe FS105 Ethernet Switch - FS105NA</td>\n",
       "      <td>NETGEAR FS105 Prosafe 5 Port 10/100 Desktop Sw...</td>\n",
       "      <td>Netgear</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id                                               name  \\\n",
       "0  10011646  Linksys EtherFast EZXS88W Ethernet Switch - EZ...   \n",
       "1  10140760          Linksys EtherFast EZXS55W Ethernet Switch   \n",
       "2  10221960    Netgear ProSafe FS105 Ethernet Switch - FS105NA   \n",
       "\n",
       "                                         description manufacturer price  \n",
       "0  Linksys EtherFast 8-Port 10/100 Switch (New/Wo...      LINKSYS   NaN  \n",
       "1                              5 x 10/100Base-TX LAN      LINKSYS   NaN  \n",
       "2  NETGEAR FS105 Prosafe 5 Port 10/100 Desktop Sw...      Netgear   NaN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "➜ After cleaning — Abt sample:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prod_id</th>\n",
       "      <th>source</th>\n",
       "      <th>name</th>\n",
       "      <th>title_clean</th>\n",
       "      <th>brand_norm</th>\n",
       "      <th>price</th>\n",
       "      <th>price_bucket</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>552</td>\n",
       "      <td>abt</td>\n",
       "      <td>Sony Turntable - PSLX350H</td>\n",
       "      <td>sony turntable pslx350h</td>\n",
       "      <td>sony</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>580</td>\n",
       "      <td>abt</td>\n",
       "      <td>Bose Acoustimass 5 Series III Speaker System -...</td>\n",
       "      <td>bose acoustimass 5 series iii speaker system a...</td>\n",
       "      <td>bose</td>\n",
       "      <td>399.0</td>\n",
       "      <td>200-499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4696</td>\n",
       "      <td>abt</td>\n",
       "      <td>Sony Switcher - SBV40S</td>\n",
       "      <td>sony switcher sbv40s</td>\n",
       "      <td>sony</td>\n",
       "      <td>49.0</td>\n",
       "      <td>0-49</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  prod_id source                                               name  \\\n",
       "0     552    abt                          Sony Turntable - PSLX350H   \n",
       "1     580    abt  Bose Acoustimass 5 Series III Speaker System -...   \n",
       "2    4696    abt                             Sony Switcher - SBV40S   \n",
       "\n",
       "                                         title_clean brand_norm  price  \\\n",
       "0                            sony turntable pslx350h       sony    NaN   \n",
       "1  bose acoustimass 5 series iii speaker system a...       bose  399.0   \n",
       "2                               sony switcher sbv40s       sony   49.0   \n",
       "\n",
       "  price_bucket  \n",
       "0               \n",
       "1      200-499  \n",
       "2         0-49  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "➜ After cleaning — Buy sample:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prod_id</th>\n",
       "      <th>source</th>\n",
       "      <th>name</th>\n",
       "      <th>title_clean</th>\n",
       "      <th>brand_norm</th>\n",
       "      <th>price</th>\n",
       "      <th>price_bucket</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10011646</td>\n",
       "      <td>buy</td>\n",
       "      <td>Linksys EtherFast EZXS88W Ethernet Switch - EZ...</td>\n",
       "      <td>linksys etherfast ezxs88w ethernet switch ezxs88w</td>\n",
       "      <td>linksys</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10140760</td>\n",
       "      <td>buy</td>\n",
       "      <td>Linksys EtherFast EZXS55W Ethernet Switch</td>\n",
       "      <td>linksys etherfast ezxs55w ethernet switch</td>\n",
       "      <td>linksys</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10221960</td>\n",
       "      <td>buy</td>\n",
       "      <td>Netgear ProSafe FS105 Ethernet Switch - FS105NA</td>\n",
       "      <td>netgear prosafe fs105 ethernet switch fs105na</td>\n",
       "      <td>netgear</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    prod_id source                                               name  \\\n",
       "0  10011646    buy  Linksys EtherFast EZXS88W Ethernet Switch - EZ...   \n",
       "1  10140760    buy          Linksys EtherFast EZXS55W Ethernet Switch   \n",
       "2  10221960    buy    Netgear ProSafe FS105 Ethernet Switch - FS105NA   \n",
       "\n",
       "                                         title_clean brand_norm  price  \\\n",
       "0  linksys etherfast ezxs88w ethernet switch ezxs88w    linksys    NaN   \n",
       "1          linksys etherfast ezxs55w ethernet switch    linksys    NaN   \n",
       "2      netgear prosafe fs105 ethernet switch fs105na    netgear    NaN   \n",
       "\n",
       "  price_bucket  \n",
       "0               \n",
       "1               \n",
       "2               "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#  Global Imports and Environment Setup\n",
    "\n",
    "# Load API Key from .env file\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "# Future annotations for type hints\n",
    "from __future__ import annotations\n",
    "\n",
    "# Standard Libraries\n",
    "import os, re, json, math, shelve, atexit, hashlib, random, itertools, asyncio, time, textwrap\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "from collections import Counter\n",
    "import concurrent.futures as cf\n",
    "\n",
    "# Third-Party Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tqdm\n",
    "\n",
    "from pydantic import BaseModel\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_neo4j import Neo4jGraph\n",
    "from langgraph.graph import StateGraph, END\n",
    "import tenacity\n",
    "import openai\n",
    "\n",
    "# Jupyter notebook display utilities\n",
    "from IPython.display import display\n",
    "\n",
    "print(\"Imports & environment ready\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Direct pipeline to the correct files \n",
    "DATA_DIR = Path(\"/Users/arodriguez/Python_/Python_/Environment1/Research/entity_resolution_agent\")\n",
    "ABT_CSV  = DATA_DIR / \"Abt.csv\"\n",
    "BUY_CSV  = DATA_DIR / \"Buy.csv\"\n",
    "\n",
    "# Load our data files \n",
    "ENC = \"latin1\"  # Encoding used in the original CSV files\n",
    "abt = pd.read_csv(ABT_CSV, encoding=ENC, engine=\"python\") \n",
    "buy = pd.read_csv(BUY_CSV, encoding=ENC, engine=\"python\")\n",
    "\n",
    "# Show raw tables before any cleaning\n",
    "print(\"➜ Before cleaning — Abt sample:\")\n",
    "display(abt.head(3))\n",
    "print(\"➜ Before cleaning — Buy sample:\")\n",
    "display(buy.head(3))\n",
    "\n",
    "# Build a stable unique identifier for each product\n",
    "abt[\"prod_id\"] = abt[\"id\"].astype(str)\n",
    "buy[\"prod_id\"] = buy[\"id\"].astype(str)\n",
    "\n",
    "# Create a unique identifier to know which table a product comes from\n",
    "abt[\"source\"] = \"abt\"\n",
    "buy[\"source\"] = \"buy\"\n",
    "\n",
    "# Very Light Cleaning to make the data more consistent (lower-case, strip punctuation and whitespace)\n",
    "def clean_text(s: str) -> str:\n",
    "    s = str(s).lower()\n",
    "    s = re.sub(r\"[^a-z0-9 ]\", \" \", s)\n",
    "    return re.sub(r\"\\s+\", \" \", s).strip()\n",
    "\n",
    "def brand_from_title(title: str) -> str:\n",
    "    m = re.match(r\"([a-zA-Z0-9]+)\", str(title))\n",
    "    return m.group(1).lower() if m else \"\"\n",
    "\n",
    "# Define price buckets based on the price ranges\n",
    "def price_bucket(price) -> str:\n",
    "    if price is None or (isinstance(price, float) and math.isnan(price)):\n",
    "        return \"\"\n",
    "    p = float(price)\n",
    "    if   p <  50:  return \"0-49\"\n",
    "    elif p < 100:  return \"50-99\"\n",
    "    elif p < 200:  return \"100-199\"\n",
    "    elif p < 500:  return \"200-499\"\n",
    "    else:          return \"500+\"\n",
    "\n",
    "# Apply cleaning functions to both dataframes\n",
    "for df in (abt, buy):\n",
    "    # normalize prices\n",
    "    df[\"price\"] = (\n",
    "        df[\"price\"]\n",
    "          .astype(str)\n",
    "          .str.replace(r\"[^\\d.]\", \"\", regex=True)\n",
    "          .replace(\"\", float(\"nan\"))\n",
    "          .astype(float)\n",
    "    )\n",
    "    df[\"price_bucket\"] = df[\"price\"].map(price_bucket)\n",
    "\n",
    "    # clean titles & extract brand token\n",
    "    df[\"title_clean\"] = df[\"name\"].map(clean_text)\n",
    "    df[\"brand_norm\"]  = df[\"name\"].map(brand_from_title)\n",
    "\n",
    "# Show small sample after cleaning\n",
    "print(\"\\n➜ After cleaning — Abt sample:\")\n",
    "display(abt[[\"prod_id\",\"source\",\"name\",\"title_clean\",\"brand_norm\",\"price\",\"price_bucket\"]].head(3))\n",
    "print(\"➜ After cleaning — Buy sample:\")\n",
    "display(buy[[\"prod_id\",\"source\",\"name\",\"title_clean\",\"brand_norm\",\"price\",\"price_bucket\"]].head(3))\n",
    "\n",
    "# Concatenate the two dataframes into a single one\n",
    "df = pd.concat([abt, buy], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this step, we are loading our data and performing very light cleaning on our datasets. We want to create unique indentifiers for the products to ensure that when we are looking for matches we are comparing correctly. This step is important because we want our product name, brands and prices to be uniform. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows in perfectMapping : 1097\n",
      "✅ Gold pairs ready : 1,097\n"
     ]
    }
   ],
   "source": [
    "# Load the perfectMapping csv file which contains our ground truth pairs\n",
    "GOLD_CSV = DATA_DIR / \"abt_buy_perfectMapping.csv\"\n",
    "\n",
    "# Reading the perfectMapping CSV file and showing the number of rows\n",
    "gold_raw = pd.read_csv(GOLD_CSV, encoding=\"latin1\", engine=\"python\")\n",
    "print(\"Rows in perfectMapping :\", len(gold_raw))\n",
    "\n",
    "# Build a lookup table from our master dataframe which was created in the previous step\n",
    "orig_to_pid = (\n",
    "    df[[\"id\", \"source\", \"prod_id\"]]          \n",
    "      .set_index([\"source\", \"id\"])[\"prod_id\"]\n",
    "      .to_dict()\n",
    ")\n",
    "# Define a function to convert original IDs to product IDs\n",
    "def to_pid(src:str, orig_id)->str|None:\n",
    "    return orig_to_pid.get((src, orig_id))\n",
    "\n",
    "# Add converted product IDs to the gold_raw DataFrame\n",
    "gold_raw[\"pid_abt\"] = gold_raw[\"idAbt\"].map(lambda x: to_pid(\"abt\", x))\n",
    "gold_raw[\"pid_buy\"] = gold_raw[\"idBuy\"].map(lambda x: to_pid(\"buy\", x))\n",
    "\n",
    "# Drop rows that could not be converted to product IDs \n",
    "gold = gold_raw.dropna(subset=[\"pid_abt\", \"pid_buy\"]).copy()\n",
    "# Coverting each row to take two product IDs as tuples do prod_1 and prod_2 are treated as the same pair as prod_2 and prod_1\n",
    "gold_pairs = {tuple(sorted(t)) for t in gold[[\"pid_abt\", \"pid_buy\"]].values}\n",
    "print(f\" Gold pairs ready : {len(gold_pairs):,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this step we are loading our ground truth to be able to test the accuracy and recall of our pipeline. This is important because in our ground truth we only have comparisons between abt -> buy, we don't have buy -> buy pairs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.  garmin deluxe carrying case black finish 0101023101  ↔  garmin canvas deluxe carry case 010 10231 01\n",
      "2.  samsung ht bd2t blu ray 7 1 home theater system blu ray dvd   ↔  samsung 7 1 channel blu ray home theater system htbd2txaa\n",
      "3.  danby ddw497w countertop dishwasher  ↔  danby white countertop dishwasher ddw497wh\n",
      "4.  panasonic hd 3mos 60gb hard disk drive sd hybrid camcorder w  ↔  panasonic black high defintion 60gb hard disk drive sd hybri\n",
      "5.  garmin suction cup mount 010 10936 00  ↔  garmin vehicle suction cup mount 0101093600\n"
     ]
    }
   ],
   "source": [
    "# Display a few random pairs from the gold standard (ground truth)\n",
    "for i,(a,b) in enumerate(random.sample(list(gold_pairs), 5),1):\n",
    "    ta = df.loc[df.prod_id==a, \"title_clean\"].values[0]\n",
    "    tb = df.loc[df.prod_id==b, \"title_clean\"].values[0]\n",
    "    print(f\"{i}.  {ta[:60]}  ↔  {tb[:60]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows ready → 2173\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Neo4j ingest: 100%|██████████| 1/1 [00:00<00:00,  2.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅  Product nodes now: 2173\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Pushing our cleaned data into Neo4j                                \n",
    "# Connect to Neo4j database through the use of Docker who is hosting our instance\n",
    "kb = Neo4jGraph(\n",
    "    url      = \"bolt://localhost:7688\", # This is the port where Neo4j is running\n",
    "    username = \"neo4j\",     \n",
    "    password = \"testpass\",\n",
    "    refresh_schema = False, # Disable automatic schema refresh\n",
    "    sanitize       = False, # Disable sanitization of input data\n",
    "    driver_config  = {\n",
    "        \"notifications_min_severity\": \"NONE\"\n",
    "    }\n",
    ")\n",
    "\n",
    "# Create a one-time constraint to ensure prod_id is unique for Product nodes \n",
    "kb.query(\"\"\"\n",
    "CREATE CONSTRAINT product_pk IF NOT EXISTS\n",
    "FOR (p:Product) REQUIRE p.prod_id IS UNIQUE\n",
    "\"\"\")\n",
    "\n",
    "# Prepare the data for ingestion into Neo4j\n",
    "keep_cols = [\n",
    "    \"prod_id\",      # primary key\n",
    "    \"source\",       # 'abt' / 'buy'\n",
    "    \"name\",         # raw product title \n",
    "    \"title_clean\",  # cleaned-up title\n",
    "    \"brand_norm\",   # cleaned-up brand\n",
    "    \"price\"         # may be NaN / empty\n",
    "]\n",
    "\n",
    "# Concatenate the two dataframes into a single one for ingestion\n",
    "ingest_df = pd.concat([abt[keep_cols], buy[keep_cols]], ignore_index=True)\n",
    "\n",
    "# Ensure all columns are of the correct type\n",
    "for col in [\"prod_id\", \"source\", \"name\", \"title_clean\", \"brand_norm\"]:\n",
    "    ingest_df[col] = ingest_df[col].fillna(\"\").astype(str)\n",
    "\n",
    "# Ensure price is a float, filling NaNs with 0.0\n",
    "ingest_df[\"price\"] = ingest_df[\"price\"].fillna(0.0).astype(float)\n",
    "\n",
    "# Convert the DataFrame to a list of dictionaries for bulk ingestion\n",
    "rows = ingest_df.to_dict(\"records\")\n",
    "print(\"Rows ready →\", len(rows))\n",
    "\n",
    "# Cypher query for bulk ingestion of Product nodes \n",
    "cypher = \"\"\"\n",
    "UNWIND $batch AS row\n",
    "MERGE (p:Product {prod_id: row.prod_id})\n",
    "SET   p.source      = row.source,\n",
    "      p.name        = row.name,\n",
    "      p.title_clean = row.title_clean,\n",
    "      p.brand_norm  = row.brand_norm,\n",
    "      p.price       = toFloat(row.price)\n",
    "\"\"\"\n",
    "\n",
    "# Ingest the data in batches to avoid overwhelming the database\n",
    "BATCH = 5_000\n",
    "for start in tqdm.tqdm(range(0, len(rows), BATCH), desc=\"Neo4j ingest\"):\n",
    "    kb.query(cypher, params={\"batch\": rows[start : start + BATCH]})\n",
    "\n",
    "print(\" Product nodes now:\",\n",
    "      kb.query(\"MATCH (:Product) RETURN count(*) AS n\")[0][\"n\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we are establishing a connection with Docker for it to host our Neo4j instance locally. We then begin preparing our data for ingestion. Firstly we want to create a one-time-uniqueness constraint, what this means is that if we were to add rows to our data our previous ingestion would not be carried over and only the new changes will be ingested. With a cypher is how we communicate to Neo4j how we want our data to be stored. Lastly we want to do this in batches to avoid crashes and ensure that its a smooth process. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "helper rows: 100%|██████████| 2173/2173 [00:01<00:00, 1936.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Helper rels added for 2,173 products\n",
      "• distinct brands   : 155\n",
      "• distinct name-toks: 3369\n"
     ]
    }
   ],
   "source": [
    "# Creation of helper nodes and relationships for brands and name tokens\n",
    "\n",
    "# Ensure the DataFrame has the necessary columns for helper nodes\n",
    "for col in [\"brand_norm\", \"title_clean\"]:\n",
    "    df[col] = df[col].fillna(\"\").astype(str)\n",
    "\n",
    "# Define a set of stop words to ignore in name tokens (we want to focus on meaningful tokens)\n",
    "STOP = {\"the\", \"and\", \"for\", \"with\", \"inch\", \"cm\", \"mm\"}\n",
    "def name_tokens(title: str):\n",
    "    for tok in re.split(r\"\\W+\", title.lower()):\n",
    "        if len(tok) > 2 and tok not in STOP:\n",
    "            yield tok\n",
    "\n",
    "# Create constraints for Brand and NameTok nodes to ensure uniqueness\n",
    "kb.query(\"CREATE CONSTRAINT brand_pk IF NOT EXISTS FOR (b:Brand)  REQUIRE b.name IS UNIQUE\")\n",
    "kb.query(\"CREATE CONSTRAINT tok_pk   IF NOT EXISTS FOR (t:NameTok) REQUIRE t.tok  IS UNIQUE\")\n",
    "\n",
    "# Cypher query to create helper nodes and relationships\n",
    "cypher = \"\"\"\n",
    "UNWIND $rows AS row\n",
    "MATCH (p:Product {prod_id: row.prod_id})\n",
    "\n",
    "/* Brand helper */\n",
    "WITH p, row\n",
    "WHERE row.brand <> \"\"\n",
    "MERGE (b:Brand {name: row.brand})\n",
    "MERGE (p)-[:HAS_BRAND]->(b)\n",
    "\n",
    "/* Name-token helpers */\n",
    "WITH p, row\n",
    "UNWIND row.name_toks AS tok\n",
    "MERGE (t:NameTok {tok: tok})\n",
    "MERGE (p)-[:HAS_TOK]->(t)\n",
    "\"\"\"\n",
    "\n",
    "# Once again, we will ingest the data in batches to avoid overwhelming the database\n",
    "BATCH = 2_000\n",
    "sent = 0\n",
    "payload = []\n",
    "\n",
    "for rec in tqdm.tqdm(df.itertuples(index=False), total=len(df), desc=\"helper rows\"):\n",
    "    d = rec._asdict()\n",
    "    payload.append({\n",
    "        \"prod_id\": d[\"prod_id\"],\n",
    "        \"brand\":   d[\"brand_norm\"],\n",
    "        \"name_toks\": list(name_tokens(d[\"title_clean\"])),\n",
    "    })\n",
    "    if len(payload) == BATCH:\n",
    "        kb.query(cypher, params={\"rows\": payload})\n",
    "        sent += len(payload)\n",
    "        payload.clear()\n",
    "\n",
    "# Send any remaining payload that didn't fill a complete batch\n",
    "if payload:\n",
    "    kb.query(cypher, params={\"rows\": payload})\n",
    "    sent += len(payload)\n",
    "\n",
    "print(f\" Helper relationships added for {sent:,} products\")\n",
    "print(\" Distinct Brands   :\", kb.query('MATCH (:Brand)   RETURN count(*) AS n')[0]['n'])\n",
    "print(\" Distinct Name-Toks:\", kb.query('MATCH (:NameTok) RETURN count(*) AS n')[0]['n'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.\tExtract brand (we populated that column during ingestion) ⇒ connects each product to a (:Brand) node.\n",
    "2.\tTokenise the normalised title into simple word tokens ⇒ connects to (:NameTok) nodes.\n",
    "3.\tAdds uniqueness constraints so duplicates collapse to a single helper node.\n",
    "4.\tProcesses the dataframe in chunks so memory usage stays small."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"products\": [\n",
      "    {\n",
      "      \"price\": 16.0,\n",
      "      \"name\": \"Canon Cyan Photo Ink Cartridge - Cyan - CLI8PC\",\n",
      "      \"source\": \"abt\",\n",
      "      \"title_clean\": \"canon cyan photo ink cartridge cyan cli8pc\",\n",
      "      \"brand_norm\": \"canon\",\n",
      "      \"prod_id\": \"20458\"\n",
      "    },\n",
      "    {\n",
      "      \"price\": 0.0,\n",
      "      \"name\": \"LG 25.0 Cu.Ft. Total Capacity\",\n",
      "      \"source\": \"buy\",\n",
      "      \"title_clean\": \"lg 25 0 cu ft total capacity\",\n",
      "      \"brand_norm\": \"lg\",\n",
      "      \"prod_id\": \"208114672\"\n",
      "    }\n",
      "  ],\n",
      "  \"brands\": [\n",
      "    {\n",
      "      …\n"
     ]
    }
   ],
   "source": [
    "# Establish our Retrieval Cypher Query to fetch the product subgraphs\n",
    "# How many neighbours per helper, and a hard cap\n",
    "K_BRAND, K_TOK, HARD_CAP = 15, 8, 120\n",
    "\n",
    "# Function to retrieve a product subgraph based on two product IDs\n",
    "def get_product_subgraph(id1, id2) -> str | None:\n",
    "    id1, id2 = str(id1), str(id2)\n",
    "    params = {\"id1\": id1, \"id2\": id2}\n",
    "    \n",
    "    cypher = f\"\"\"\n",
    "    MATCH (a:Product {{prod_id: $id1}})\n",
    "    MATCH (b:Product {{prod_id: $id2}})\n",
    "\n",
    "    OPTIONAL MATCH (a)-[:HAS_BRAND]->(brA:Brand)\n",
    "    OPTIONAL MATCH (b)-[:HAS_BRAND]->(brB:Brand)\n",
    "    OPTIONAL MATCH (a)-[:HAS_TOK]->(tA:NameTok)\n",
    "    OPTIONAL MATCH (b)-[:HAS_TOK]->(tB:NameTok)\n",
    "\n",
    "    WITH a,b,\n",
    "         coalesce(\n",
    "           apoc.coll.toSet(collect(brA)+collect(brB)),\n",
    "           collect(distinct brA)+collect(distinct brB)\n",
    "         ) AS brands,\n",
    "         coalesce(\n",
    "           apoc.coll.toSet(collect(tA)+collect(tB)),\n",
    "           collect(distinct tA)+collect(distinct tB)\n",
    "         ) AS toks\n",
    "\n",
    "    // ── rank brand neighbours by price distance ──────────────────────────────\n",
    "    UNWIND brands AS br\n",
    "    MATCH (br)<-[:HAS_BRAND]-(p1:Product)\n",
    "    WHERE NOT p1.prod_id IN [$id1,$id2]\n",
    "    WITH a,b,brands,toks,p1\n",
    "    ORDER BY abs(p1.price - a.price)\n",
    "    WITH a,b,brands,toks,\n",
    "         collect(distinct p1)[0..{K_BRAND}] AS via_brand\n",
    "\n",
    "    // ── rank token neighbours by title Levenshtein distance ──────────────────\n",
    "    UNWIND toks AS t\n",
    "    MATCH (t)<-[:HAS_TOK]-(p2:Product)\n",
    "    WHERE NOT p2.prod_id IN [$id1,$id2]\n",
    "    WITH a,b,brands,toks,via_brand,p2\n",
    "    ORDER BY apoc.text.levenshteinDistance(a.title_clean, p2.title_clean)\n",
    "    WITH a,b,brands,toks,via_brand,\n",
    "         collect(distinct p2)[0..{K_TOK}] AS via_tok\n",
    "\n",
    "    WITH a,b,\n",
    "         brands      AS brand_nodes,\n",
    "         toks        AS tok_nodes,\n",
    "         apoc.coll.toSet(via_brand + via_tok)[0..{HARD_CAP}] AS others\n",
    "    RETURN\n",
    "         [a,b]       AS products,\n",
    "         brand_nodes AS brands,\n",
    "         tok_nodes   AS tokens,\n",
    "         others      AS neighbours\n",
    "    \"\"\"\n",
    "\n",
    "    result = kb.query(cypher, params)\n",
    "    if not result:\n",
    "        return None\n",
    "    rec = result[0]\n",
    "\n",
    "    def serialise(node):\n",
    "        return {\"labels\": list(node.labels), **node._properties} if hasattr(node, \"labels\") else node\n",
    "\n",
    "    payload = {\n",
    "        \"products\"  : [serialise(n) for n in rec[\"products\"]],\n",
    "        \"brands\"    : [serialise(n) for n in rec[\"brands\"]],\n",
    "        \"tokens\"    : [serialise(n) for n in rec[\"tokens\"]],\n",
    "        \"neighbours\": [serialise(n) for n in rec[\"neighbours\"]],\n",
    "    }\n",
    "    return json.dumps(payload, ensure_ascii=False, indent=2)\n",
    "\n",
    "# Sanity check to ensure that we are fetching one product from each file\n",
    "idA = random.choice([i for i in abt[\"prod_id\"]])\n",
    "idB = random.choice([i for i in buy[\"prod_id\"]])\n",
    "print(get_product_subgraph(idA, idB)[:500], \"…\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅  LangGraph re-compiled  (static prompts + human override)\n",
      "\n",
      "🆚  36502 ↔ 203136102\n",
      "Agent A  : NO    │ brands differ\n",
      "Agent B  : 0.05\n",
      "Manager  : NO_MATCH\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# LangGraph — Multi-Agent Entity Resolution System\n",
    "\n",
    "# Setup LangGraph multi-agent system for entity resolution\n",
    "# This creates a workflow with two AI agents (A & B) plus a manager to decide if products match\n",
    "\n",
    "from __future__ import annotations\n",
    "import json, re, random, textwrap, hashlib\n",
    "from datetime import datetime\n",
    "from pydantic import BaseModel\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langgraph.graph import StateGraph, END\n",
    "\n",
    "# Configure decision thresholds for the Manager agent\n",
    "PB_HIGH = 0.60   # If Agent-B confidence ≥ 0.60 → MATCH\n",
    "PB_LOW  = 0.40   # If Agent-B confidence ≤ 0.40 → NO_MATCH\n",
    "\n",
    "# Initialize our main language model for the agents\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "\n",
    "# Dynamic Few-Shot Learning: Pull human-labeled examples from Neo4j\n",
    "# This helps the AI agents learn from previous human decisions\n",
    "HUMAN_LIMIT = 5\n",
    "human_exs = kb.query(f\"\"\"\n",
    "MATCH (h:HumanLabel)-[:RESOLVES]->(a:Product),\n",
    "      (h)-[:RESOLVES]->(b:Product)\n",
    "WHERE h.label IN ['MATCH','NO_MATCH']\n",
    "RETURN h.label AS label,\n",
    "       a.title_clean AS titleA, a.brand_norm AS brandA, a.price AS priceA,\n",
    "       b.title_clean AS titleB, b.brand_norm AS brandB, b.price AS priceB\n",
    "LIMIT {HUMAN_LIMIT}\n",
    "\"\"\")\n",
    "\n",
    "# Build dynamic examples for Agent B from human labels\n",
    "# Convert human decisions into training examples with probability scores\n",
    "dynamic_B = []\n",
    "for ex in human_exs:\n",
    "    # Calculate price difference as percentage\n",
    "    gap = abs(ex[\"priceA\"] - ex[\"priceB\"]) / max(ex[\"priceA\"] or 1, ex[\"priceB\"] or 1) * 100\n",
    "    blob = json.dumps({\n",
    "        \"titleA\": ex[\"titleA\"], \"brandA\": ex[\"brandA\"],\n",
    "        \"titleB\": ex[\"titleB\"], \"brandB\": ex[\"brandB\"],\n",
    "        \"price_gap_pct\": round(gap,1)\n",
    "    })\n",
    "    # Convert human label to probability: MATCH=1.00, NO_MATCH=0.00\n",
    "    p = 1.00 if ex[\"label\"] == \"MATCH\" else 0.00\n",
    "    dynamic_B.append(f\"{p:.2f}\\n{blob}\")\n",
    "\n",
    "# Static training examples for Agent A (categorical decisions)\n",
    "# These are hardcoded examples to guide Agent A's YES/NO/UNSURE decisions\n",
    "FEWSHOT_A = \"\"\"\\\n",
    "Example-1 (same)       → YES – identical title+brand\n",
    "{\"title_clean\":\"sony cyber-shot dsc-h3 digital camera 8mp\",\"brand_norm\":\"sony\",\"price\":249.99}\n",
    "{\"title_clean\":\"sony cyber-shot dsc-h3 8 megapixel camera\",\"brand_norm\":\"sony\",\"price\":249.99}\n",
    "\n",
    "Example-2 (different)  → NO – brands differ\n",
    "{\"title_clean\":\"apple iphone 12 64gb black\",\"brand_norm\":\"apple\",\"price\":799}\n",
    "{\"title_clean\":\"samsung galaxy s21 128gb phantom gray\",\"brand_norm\":\"samsung\",\"price\":799}\n",
    "\n",
    "Example-3 (uncertain)  → UNSURE – title overlap / price far\n",
    "{\"title_clean\":\"hp pavilion 15-eg laptop i7\",\"brand_norm\":\"hp\",\"price\":699}\n",
    "{\"title_clean\":\"hp pavilion laptop 15.6 inch\",\"brand_norm\":\"hp\",\"price\":999}\n",
    "\"\"\"\n",
    "\n",
    "# Combined training examples for Agent B (probability scoring)\n",
    "# Static examples + dynamic examples from human labels\n",
    "FEWSHOT_B = \"\"\"\\\n",
    "0.95\n",
    "{\"titleA\":\"sony cyber-shot dsc-h3 digital camera 8mp\",\"brandA\":\"sony\",\n",
    " \"titleB\":\"sony cyber-shot dsc-h3 8-megapixel camera\",\"brandB\":\"sony\",\n",
    " \"price_gap_pct\":0.0}\n",
    "…\n",
    "0.05\n",
    "{\"titleA\":\"canon eos r10 mirrorless camera\",\"brandA\":\"canon\",\n",
    " \"titleB\":\"dell inspiron 15 laptop\",\"brandB\":\"dell\",\n",
    " \"price_gap_pct\":250.0}\n",
    "\"\"\" + \"\\n\\n\" + \"\\n\\n\".join(dynamic_B)\n",
    "\n",
    "# Define the state structure that flows through our LangGraph workflow\n",
    "# This tracks all information as it moves between agents\n",
    "class ERState(BaseModel):\n",
    "    id1: str                    # First product ID\n",
    "    id2: str                    # Second product ID\n",
    "    graph_ctx    : dict | None = None    # Neo4j subgraph context\n",
    "    human_label  : str  | None = None    # Human override if exists\n",
    "    agentA_lbl   : str  | None = None    # Agent A's YES/NO/UNSURE decision\n",
    "    agentA_reason: str  | None = None    # Agent A's reasoning\n",
    "    agentB_prob  : float| None = None    # Agent B's probability score (0-1)\n",
    "    decision     : str  | None = None    # Final manager decision\n",
    "\n",
    "# Helper function: Check if humans have already labeled this pair\n",
    "# Looks in both directions (a,b) and (b,a) since pairs are bidirectional\n",
    "def get_human_label(a: str, b: str) -> str | None:\n",
    "    rec = kb.query(\"\"\"\n",
    "        MATCH (h:HumanLabel {id1:$a,id2:$b}) RETURN h.label AS lbl\n",
    "        UNION\n",
    "        MATCH (h:HumanLabel {id1:$b,id2:$a}) RETURN h.label AS lbl\n",
    "    \"\"\", {\"a\": a, \"b\": b})\n",
    "    return rec[0][\"lbl\"] if rec else None\n",
    "\n",
    "# Step 1: Retrieve context and check for human labels\n",
    "# Only processes Abt↔Buy pairs (skips same-source comparisons)\n",
    "def retrieve_fn(s: ERState):\n",
    "    # Extract source from product IDs (format: \"source_id\")\n",
    "    src1, src2 = s.id1.split(\"_\",1)[0], s.id2.split(\"_\",1)[0]\n",
    "    \n",
    "    # Skip if both products from same source (abt-abt or buy-buy)\n",
    "    if src1 == src2:\n",
    "        return {\"graph_ctx\": None, \"human_label\": None}\n",
    "    \n",
    "    # Check if humans have already labeled this pair\n",
    "    hl  = get_human_label(s.id1, s.id2)\n",
    "    \n",
    "    # Get Neo4j subgraph context only if no human label exists\n",
    "    ctx = None if hl else get_product_subgraph(s.id1, s.id2)\n",
    "    return {\"graph_ctx\": json.loads(ctx) if ctx else None, \"human_label\": hl}\n",
    "\n",
    "# Step 2: Agent A - Categorical matcher (YES/UNSURE/NO decisions)\n",
    "# Uses few-shot examples to make quick categorical decisions\n",
    "def agentA_fewshot(s: ERState):\n",
    "    # Return UNSURE if no context available\n",
    "    if s.graph_ctx is None:\n",
    "        return {\"agentA_lbl\":\"UNSURE\",\"agentA_reason\":\"missing context\"}\n",
    "    \n",
    "    # Build prompt with guidelines and examples\n",
    "    prompt = f\"\"\"You are **Agent A** (categorical matcher).\n",
    "\n",
    "Return ONE line:\n",
    "YES – …reason…    /    UNSURE – …reason…    /    NO – …reason…\n",
    "(≤10 words after the dash)\n",
    "\n",
    "Guidelines\n",
    "• Exact same brand + very similar titles → YES\n",
    "• Completely different brands            → NO\n",
    "• Same brand but price gap > 30% OR fuzzy title → UNSURE\n",
    "\n",
    "{FEWSHOT_A}\n",
    "\n",
    "Pair ↓\n",
    "{s.graph_ctx}\n",
    "Answer:\"\"\"\n",
    "    \n",
    "    # Get LLM response and parse the decision\n",
    "    raw = llm.invoke(prompt).content.strip()\n",
    "    lbl,rsn = \"UNSURE\",\"\"\n",
    "    \n",
    "    # Parse the response format \"DECISION – reason\"\n",
    "    for sep in (\"–\",\"-\",\"—\",\":\"):\n",
    "        if sep in raw:\n",
    "            lbl,rsn = [x.strip() for x in raw.split(sep,1)]\n",
    "            break\n",
    "    \n",
    "    lbl=lbl.upper()\n",
    "    # Validate the decision label\n",
    "    if lbl not in {\"YES\",\"UNSURE\",\"NO\"}: \n",
    "        lbl,rsn=\"UNSURE\",\"unrecognised\"\n",
    "    \n",
    "    return {\"agentA_lbl\":lbl,\"agentA_reason\":\" \".join(rsn.split()[:10])}\n",
    "\n",
    "# Step 3: Agent B - Probability scorer (0.0 to 1.0 confidence)\n",
    "# Uses dynamic examples to output a precise match probability\n",
    "def agentB_prob(s: ERState):\n",
    "    # Return neutral probability if no context\n",
    "    if s.graph_ctx is None:\n",
    "        return {\"agentB_prob\":0.50}\n",
    "    \n",
    "    # Extract product information and calculate price gap\n",
    "    a,b = s.graph_ctx[\"products\"]\n",
    "    gap = abs((a.get(\"price\") or 0)-(b.get(\"price\") or 0)) / max(a.get(\"price\") or 1, b.get(\"price\") or 1)*100\n",
    "    \n",
    "    # Create comparison blob for the LLM\n",
    "    blob = json.dumps({\n",
    "        \"titleA\":a.get(\"title_clean\",\"\"), \"brandA\":a.get(\"brand_norm\",\"\"),\n",
    "        \"titleB\":b.get(\"title_clean\",\"\"), \"brandB\":b.get(\"brand_norm\",\"\"),\n",
    "        \"price_gap_pct\":round(gap,1)\n",
    "    })\n",
    "    \n",
    "    # Build prompt with dynamic examples\n",
    "    prompt = f\"\"\"You are Agent B (0-1 scorer).\n",
    "\n",
    "Guideline examples:\n",
    "{FEWSHOT_B}\n",
    "\n",
    "Pair:\n",
    "{blob}\n",
    "Answer:\"\"\"\n",
    "    \n",
    "    # Parse probability from LLM response\n",
    "    try:\n",
    "        p = float(re.findall(r\"\\d*\\.?\\d+\", llm.invoke(prompt).content)[0])\n",
    "    except:\n",
    "        p = 0.5  # Default to neutral if parsing fails\n",
    "    \n",
    "    # Ensure probability is between 0 and 1\n",
    "    return {\"agentB_prob\":max(0,min(1,p))}\n",
    "\n",
    "# Step 4: Manager - Makes final decision using hierarchical logic\n",
    "# Combines Agent A and Agent B outputs with configurable thresholds\n",
    "def manager_fn(s: ERState):\n",
    "    # Priority 1: Human override always wins\n",
    "    if s.human_label:\n",
    "        return {\"decision\": s.human_label}\n",
    "\n",
    "    lbl, p = s.agentA_lbl, s.agentB_prob\n",
    "\n",
    "    # Priority 2: Strong Agent-B confidence signals\n",
    "    if p >= PB_HIGH:    # High confidence (≥0.60) → MATCH\n",
    "        return {\"decision\": \"MATCH\"}\n",
    "    if p <= PB_LOW:     # Low confidence (≤0.40) → NO_MATCH\n",
    "        return {\"decision\": \"NO_MATCH\"}\n",
    "\n",
    "    # Priority 3: Mid-range confidence → use Agent-A decision\n",
    "    if lbl == \"YES\":\n",
    "        return {\"decision\": \"MATCH\"}\n",
    "    if lbl == \"NO\":\n",
    "        return {\"decision\": \"NO_MATCH\"}\n",
    "\n",
    "    # Priority 4: Everything else → need more data\n",
    "    return {\"decision\": \"NEED_MORE_DATA\"}\n",
    "\n",
    "# Step 5: Persist - Save the resolution decision to Neo4j\n",
    "# Creates Resolution nodes with relationships to both products\n",
    "def persist_fn(s: ERState):\n",
    "    # Create deterministic pair key for consistent storage\n",
    "    id_a, id_b = sorted((s.id1, s.id2))\n",
    "    pair_key = hashlib.sha1(f\"{id_a}|{id_b}\".encode()).hexdigest()\n",
    "\n",
    "    # Store resolution in Neo4j with all agent outputs\n",
    "    kb.query(\"\"\"\n",
    "    MERGE (r:Resolution {key:$k})\n",
    "      SET r.id1      = $a,\n",
    "          r.id2      = $b,\n",
    "          r.decision = $d,\n",
    "          r.agentA   = $lbl,\n",
    "          r.reason   = $rsn,\n",
    "          r.prob     = $p,\n",
    "          r.ts       = $ts\n",
    "    WITH r\n",
    "    MATCH (a:Product {prod_id:$a}), (b:Product {prod_id:$b})\n",
    "    // Create bidirectional relationships to both products\n",
    "    MERGE (r)-[e1:RESOLVES]->(a)\n",
    "      SET e1.prob = $p, e1.decision = $d\n",
    "    MERGE (r)-[e2:RESOLVES]->(b)\n",
    "      SET e2.prob = $p, e2.decision = $d\n",
    "    \"\"\", {\n",
    "        \"k\": pair_key,\n",
    "        \"a\": id_a, \"b\": id_b, \"d\": s.decision,\n",
    "        \"lbl\": s.agentA_lbl, \"rsn\": s.agentA_reason,\n",
    "        \"p\": s.agentB_prob,\n",
    "        \"ts\": datetime.utcnow().isoformat()\n",
    "    })\n",
    "    return {}\n",
    "\n",
    "# Step 6: Assemble the LangGraph workflow\n",
    "# Creates a directed graph with nodes (functions) and edges (data flow)\n",
    "sg = StateGraph(ERState)\n",
    "\n",
    "# Add all our workflow nodes\n",
    "sg.add_node(\"retrieve\", retrieve_fn)    # Get context & human labels\n",
    "sg.add_node(\"agentA\",   agentA_fewshot) # Categorical decisions\n",
    "sg.add_node(\"agentB\",   agentB_prob)    # Probability scoring\n",
    "sg.add_node(\"mgr\",      manager_fn)     # Final decision logic\n",
    "sg.add_node(\"store\",    persist_fn)     # Save to Neo4j\n",
    "\n",
    "# Define the workflow sequence\n",
    "sg.set_entry_point(\"retrieve\")         # Start here\n",
    "sg.add_edge(\"retrieve\", \"agentA\")       # Retrieve → Agent A\n",
    "sg.add_edge(\"retrieve\", \"agentB\")       # Retrieve → Agent B (parallel)\n",
    "sg.add_edge(\"agentA\",   \"mgr\")          # Agent A → Manager\n",
    "sg.add_edge(\"agentB\",   \"mgr\")          # Agent B → Manager\n",
    "sg.add_edge(\"mgr\",      \"store\")        # Manager → Store\n",
    "sg.add_edge(\"store\",    END)            # Store → End\n",
    "\n",
    "# Compile the graph into an executable workflow\n",
    "product_graph = sg.compile()\n",
    "print(\"✅  LangGraph re-compiled  (static prompts + human override)\")\n",
    "\n",
    "# Step 7: Test the workflow with a pretty output function\n",
    "# This function runs a single pair through the entire workflow and displays results\n",
    "def pretty_smoke(idA, idB):\n",
    "    # Run the complete LangGraph workflow\n",
    "    out = product_graph.invoke({\"id1\": idA, \"id2\": idB})\n",
    "    \n",
    "    # Display formatted results\n",
    "    print(f\"\\n🆚  {idA} ↔ {idB}\")\n",
    "    print(f\"Agent A  : {out['agentA_lbl']:<6}│ {out['agentA_reason']}\")\n",
    "    print(f\"Agent B  : {out['agentB_prob']:.2f}\")\n",
    "    if out.get(\"human_label\"):\n",
    "        print(f\"⚠️  Human override → {out['human_label']}\")\n",
    "    print(f\"Manager  : {out['decision']}\")\n",
    "    print(\"-\" * 60)\n",
    "\n",
    "# Demo: Test with one random product from each catalog\n",
    "from random import choice\n",
    "idA = choice([i for i in abt[\"prod_id\"]])  # Random Abt product\n",
    "idB = choice([i for i in buy[\"prod_id\"]])  # Random Buy product\n",
    "pretty_smoke(idA, idB)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What this does\n",
    "1. Matches the two focal Product nodes (a, b).\n",
    "2. Collects their Brand and NameTok helper nodes.\n",
    "3. Pulls in a limited number of other products that share those helpers.\n",
    "4. Trims everything to a hard cap so the prompt stays small.\n",
    "5. Serialises to JSON so the LangGraph agents can consume it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total candidates after union: 156,188\n",
      "⚡ Evaluating 1091 gold + 500 negs → total 1591\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 1591/1591 [16:12<00:00,  1.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Decision counts → Counter({'MATCH': 1046, 'NO_MATCH': 524, 'NEED_MORE_DATA': 21})\n",
      "\n",
      "Precision 0.98   |   Recall 0.94\n",
      "\n",
      "Top-10 MATCHes by Agent-B probability\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id1</th>\n",
       "      <th>id2</th>\n",
       "      <th>title1</th>\n",
       "      <th>title2</th>\n",
       "      <th>prob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>33921</td>\n",
       "      <td>207925431</td>\n",
       "      <td>panasonic black dvd home theater sound system ...</td>\n",
       "      <td>panasonic sc pt660 home theater system</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>34948</td>\n",
       "      <td>208114675</td>\n",
       "      <td>lg 25 0 cu ft titanium french door bottom free...</td>\n",
       "      <td>lg 25 0 cu ft total capacity</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>35276</td>\n",
       "      <td>208084021</td>\n",
       "      <td>pioneer kuro 50 black plasma hdtv pdp5020fd</td>\n",
       "      <td>pioneer pdp 5020fd 50 plasma tv</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>32625</td>\n",
       "      <td>201935116</td>\n",
       "      <td>logitech dinovo media desktop laser keyboard a...</td>\n",
       "      <td>logitech dinovo media desktop laser 967562 0403</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>36168</td>\n",
       "      <td>208171630</td>\n",
       "      <td>flip video f360 black mino series camcorder f360b</td>\n",
       "      <td>pure digital flip mino digital camcorder f360b</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>25413</td>\n",
       "      <td>90049795</td>\n",
       "      <td>sony minidv cleaning cassette dvm12cld</td>\n",
       "      <td>sony minidv head cleaner dvm12cld</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>37183</td>\n",
       "      <td>209656949</td>\n",
       "      <td>apple 32gb black 2nd generation ipod touch mb5...</td>\n",
       "      <td>apple ipod touch 32gb flash portable media pla...</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>37310</td>\n",
       "      <td>209901966</td>\n",
       "      <td>sony vaio cs series red notebook computer vgnc...</td>\n",
       "      <td>sony vaio cs series vgn cs180j r 14 1 inch not...</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>33453</td>\n",
       "      <td>207876535</td>\n",
       "      <td>yamaha 7 2 channel black digital home theater ...</td>\n",
       "      <td>yamaha rx v863 home theater receiver rxv863bl</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>24493</td>\n",
       "      <td>202900030</td>\n",
       "      <td>panasonic 2 line integrated phone system white...</td>\n",
       "      <td>panasonic kx ts3282w corded telephone</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id1        id2                                             title1  \\\n",
       "0  33921  207925431  panasonic black dvd home theater sound system ...   \n",
       "1  34948  208114675  lg 25 0 cu ft titanium french door bottom free...   \n",
       "2  35276  208084021        pioneer kuro 50 black plasma hdtv pdp5020fd   \n",
       "3  32625  201935116  logitech dinovo media desktop laser keyboard a...   \n",
       "4  36168  208171630  flip video f360 black mino series camcorder f360b   \n",
       "5  25413   90049795             sony minidv cleaning cassette dvm12cld   \n",
       "6  37183  209656949  apple 32gb black 2nd generation ipod touch mb5...   \n",
       "7  37310  209901966  sony vaio cs series red notebook computer vgnc...   \n",
       "8  33453  207876535  yamaha 7 2 channel black digital home theater ...   \n",
       "9  24493  202900030  panasonic 2 line integrated phone system white...   \n",
       "\n",
       "                                              title2  prob  \n",
       "0             panasonic sc pt660 home theater system  0.95  \n",
       "1                       lg 25 0 cu ft total capacity  0.95  \n",
       "2                    pioneer pdp 5020fd 50 plasma tv  0.95  \n",
       "3    logitech dinovo media desktop laser 967562 0403  0.95  \n",
       "4     pure digital flip mino digital camcorder f360b  0.95  \n",
       "5                  sony minidv head cleaner dvm12cld  0.95  \n",
       "6  apple ipod touch 32gb flash portable media pla...  0.95  \n",
       "7  sony vaio cs series vgn cs180j r 14 1 inch not...  0.95  \n",
       "8      yamaha rx v863 home theater receiver rxv863bl  0.95  \n",
       "9              panasonic kx ts3282w corded telephone  0.95  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top-10 NO_MATCHes by Agent-B probability\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id1</th>\n",
       "      <th>id2</th>\n",
       "      <th>title1</th>\n",
       "      <th>title2</th>\n",
       "      <th>prob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>34349</td>\n",
       "      <td>202827684</td>\n",
       "      <td>samsung 37 series 5 lcd black flat panel hdtv ...</td>\n",
       "      <td>sanus visionmount flat panel tv wall mount mf1...</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>33021</td>\n",
       "      <td>203154818</td>\n",
       "      <td>electrolux harmony series canister vacuum el6985b</td>\n",
       "      <td>harmony el6985a vacuum canister hepa</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>36931</td>\n",
       "      <td>208370418</td>\n",
       "      <td>speck black toughskin case for iphone 3g iph3g...</td>\n",
       "      <td>3g iphone black toughskin iph3g blk ts</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6284</td>\n",
       "      <td>202812567</td>\n",
       "      <td>bose 27028 161 bookshelf pair speakers in whit...</td>\n",
       "      <td>boss 161 speaker</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>24153</td>\n",
       "      <td>208715855</td>\n",
       "      <td>whirlpool 10 whp1000sq duet washer and dryer w...</td>\n",
       "      <td>pedistal for duet sport electric washer dryer ...</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>32906</td>\n",
       "      <td>203324965</td>\n",
       "      <td>sirius dock and play universal vehicle kit supv1</td>\n",
       "      <td>directed electronics supv1 car kit</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>36452</td>\n",
       "      <td>209208655</td>\n",
       "      <td>samsung 52 series 8 lcd black flat panel hdtv ...</td>\n",
       "      <td>ln52a860 52 lcd tv widescreen 1920x1080 hdtv</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>28340</td>\n",
       "      <td>208456215</td>\n",
       "      <td>whirlpool white front load washer wfw9200swh</td>\n",
       "      <td>whirlpool 27 duet washer horiz axis wp</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>16329</td>\n",
       "      <td>210521578</td>\n",
       "      <td>whirlpool 24 built in dishwasher du1100ss</td>\n",
       "      <td>whirlpool du1100xtps 24 undercounter dishwashe...</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>29892</td>\n",
       "      <td>208715736</td>\n",
       "      <td>maytag med5900tw white electric dryer med5900twh</td>\n",
       "      <td>7 0 cu ft super capacity electric dryer med5900tw</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id1        id2                                             title1  \\\n",
       "0  34349  202827684  samsung 37 series 5 lcd black flat panel hdtv ...   \n",
       "1  33021  203154818  electrolux harmony series canister vacuum el6985b   \n",
       "2  36931  208370418  speck black toughskin case for iphone 3g iph3g...   \n",
       "3   6284  202812567  bose 27028 161 bookshelf pair speakers in whit...   \n",
       "4  24153  208715855  whirlpool 10 whp1000sq duet washer and dryer w...   \n",
       "5  32906  203324965   sirius dock and play universal vehicle kit supv1   \n",
       "6  36452  209208655  samsung 52 series 8 lcd black flat panel hdtv ...   \n",
       "7  28340  208456215       whirlpool white front load washer wfw9200swh   \n",
       "8  16329  210521578          whirlpool 24 built in dishwasher du1100ss   \n",
       "9  29892  208715736   maytag med5900tw white electric dryer med5900twh   \n",
       "\n",
       "                                              title2  prob  \n",
       "0  sanus visionmount flat panel tv wall mount mf1...  0.00  \n",
       "1               harmony el6985a vacuum canister hepa  0.05  \n",
       "2             3g iphone black toughskin iph3g blk ts  0.05  \n",
       "3                                   boss 161 speaker  0.05  \n",
       "4  pedistal for duet sport electric washer dryer ...  0.05  \n",
       "5                 directed electronics supv1 car kit  0.05  \n",
       "6       ln52a860 52 lcd tv widescreen 1920x1080 hdtv  0.05  \n",
       "7             whirlpool 27 duet washer horiz axis wp  0.05  \n",
       "8  whirlpool du1100xtps 24 undercounter dishwashe...  0.05  \n",
       "9  7 0 cu ft super capacity electric dryer med5900tw  0.05  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# STEP 6 · Stress Test Evaluation: Testing our pipeline at scale               \n",
    "###############################################################################\n",
    "\n",
    "# Run our LangGraph pipeline on a large dataset to measure performance\n",
    "# This combines candidate generation + LLM evaluation + precision/recall metrics\n",
    "\n",
    "import asyncio, random, time, tenacity, tqdm, openai, re, json\n",
    "from collections import Counter\n",
    "import pandas as pd\n",
    "\n",
    "# Configuration parameters for the evaluation\n",
    "CAND_LIMIT      = 5_000   # Maximum candidates (for memory management)\n",
    "NEG_SAMPLE_SIZE = 500     # How many negative examples to test\n",
    "RANDOM_SEED     = 42      # For reproducible results\n",
    "MAX_WORKERS     = 4       # Parallel processing limit\n",
    "TPM_PADDING     = 1.2     # Rate limiting: pause between API calls  \n",
    "MAX_RETRIES     = 6       # Retry failed API calls\n",
    "\n",
    "# Part A: Generate candidate pairs using multiple blocking strategies\n",
    "# Combine pandas-based blocking with Neo4j graph-based candidate generation\n",
    "\n",
    "# Strategy 1: Pandas blocking on brand + price bucket\n",
    "abt_block = abt[[\"prod_id\",\"brand_norm\",\"price_bucket\"]].copy()\n",
    "buy_block = buy[[\"prod_id\",\"brand_norm\",\"price_bucket\"]].copy()\n",
    "\n",
    "# Find products with same brand and price range\n",
    "blk1 = pd.merge(abt_block, buy_block,\n",
    "                on=[\"brand_norm\",\"price_bucket\"],\n",
    "                suffixes=(\"_abt\",\"_buy\"))[[\"prod_id_abt\",\"prod_id_buy\"]]\n",
    "\n",
    "# Strategy 2: Pandas blocking on first token of title\n",
    "abt_tok = abt[[\"prod_id\",\"title_clean\"]].copy().assign(\n",
    "    first_tok=lambda df: df[\"title_clean\"].str.split().str[0]\n",
    ")\n",
    "buy_tok = buy[[\"prod_id\",\"title_clean\"]].copy().assign(\n",
    "    first_tok=lambda df: df[\"title_clean\"].str.split().str[0]\n",
    ")\n",
    "\n",
    "# Find products with same starting word\n",
    "blk2 = pd.merge(abt_tok, buy_tok,\n",
    "                on=\"first_tok\",\n",
    "                suffixes=(\"_abt\",\"_buy\"))[[\"prod_id_abt\",\"prod_id_buy\"]]\n",
    "\n",
    "# Combine both pandas strategies\n",
    "cand_pb = {(a,b) for a,b in zip(blk1[\"prod_id_abt\"], blk1[\"prod_id_buy\"])}\n",
    "cand_pb |= {(a,b) for a,b in zip(blk2[\"prod_id_abt\"], blk2[\"prod_id_buy\"])}\n",
    "\n",
    "# Strategy 3: Neo4j graph-based candidate generation\n",
    "# Find products connected through shared brands or name tokens\n",
    "neo = kb.query(\"\"\"\n",
    "CALL {\n",
    "  MATCH (a:Product)-[:HAS_BRAND]->(br:Brand)<-[:HAS_BRAND]-(b:Product)\n",
    "    WHERE a.source='abt' AND b.source='buy'\n",
    "    RETURN a.prod_id AS id1, b.prod_id AS id2\n",
    "  UNION\n",
    "  MATCH (a:Product)-[:HAS_TOK]->(t:NameTok)<-[:HAS_TOK]-(b:Product)\n",
    "    WHERE a.source='abt' AND b.source='buy'\n",
    "    RETURN a.prod_id AS id1, b.prod_id AS id2\n",
    "}\n",
    "WITH DISTINCT id1, id2\n",
    "RETURN id1, id2\n",
    "\"\"\")\n",
    "cand_neo = {(r[\"id1\"], r[\"id2\"]) for r in neo}\n",
    "\n",
    "# Union all candidate generation strategies\n",
    "all_cand = list(cand_pb | cand_neo)\n",
    "print(f\"Total candidates after union: {len(all_cand):,}\")\n",
    "\n",
    "# Part B: Create balanced evaluation set\n",
    "# Include ALL gold standard pairs + random sample of negatives for fair testing\n",
    "\n",
    "# Separate candidates into positive (gold) and negative examples\n",
    "gold_cand = [p for p in all_cand if tuple(sorted(p)) in gold_pairs]  # True matches\n",
    "others    = [p for p in all_cand if tuple(sorted(p)) not in gold_pairs]  # Potential negatives\n",
    "\n",
    "# Sample negative examples to balance the dataset\n",
    "needed_negs = min(NEG_SAMPLE_SIZE, len(others))\n",
    "random.seed(RANDOM_SEED)  # Ensure reproducible results\n",
    "neg_sample  = random.sample(others, needed_negs)\n",
    "\n",
    "# Create final evaluation set: all gold pairs + sampled negatives\n",
    "eval_pairs = gold_cand + neg_sample\n",
    "print(f\"⚡ Evaluating {len(gold_cand)} gold + {len(neg_sample)} negs → total {len(eval_pairs)}\")\n",
    "\n",
    "# Part C: Parallel execution with rate limiting and error handling\n",
    "# Process many pairs efficiently while respecting OpenAI API limits\n",
    "\n",
    "# Handle different OpenAI library versions for rate limit errors\n",
    "try:\n",
    "    RateLimitErr = openai.RateLimitError\n",
    "except AttributeError:\n",
    "    import openai.error as _oe\n",
    "    RateLimitErr = _oe.RateLimitError\n",
    "\n",
    "# Wrapper function with automatic retry logic for API failures\n",
    "@tenacity.retry(\n",
    "    reraise=True,\n",
    "    retry=tenacity.retry_if_exception_type(RateLimitErr),\n",
    "    stop=tenacity.stop_after_attempt(MAX_RETRIES),\n",
    "    wait=tenacity.wait_exponential(multiplier=2, min=2, max=30),\n",
    ")\n",
    "def safe_invoke(a: str, b: str):\n",
    "    # Run our LangGraph pipeline on one pair\n",
    "    out = product_graph.invoke({\"id1\": a, \"id2\": b})\n",
    "    time.sleep(TPM_PADDING)  # Rate limiting pause\n",
    "    return out\n",
    "\n",
    "# Set up async processing with concurrency control\n",
    "sem  = asyncio.Semaphore(MAX_WORKERS)  # Limit concurrent API calls\n",
    "loop = asyncio.get_running_loop()\n",
    "\n",
    "async def run_all(pairs):\n",
    "    \"\"\"Process all pairs in parallel with progress tracking\"\"\"\n",
    "    async def one(pair):\n",
    "        async with sem:  # Respect concurrency limit\n",
    "            return await loop.run_in_executor(None, safe_invoke, *pair)\n",
    "    \n",
    "    # Create tasks for all pairs\n",
    "    tasks = [asyncio.create_task(one(p)) for p in pairs]\n",
    "    results = []\n",
    "    \n",
    "    # Process with progress bar\n",
    "    for fut in tqdm.tqdm(asyncio.as_completed(tasks),\n",
    "                         total=len(tasks), desc=\"Evaluating\"):\n",
    "        results.append(await fut)\n",
    "    return results\n",
    "\n",
    "# Execute the evaluation\n",
    "results = await run_all(eval_pairs)\n",
    "\n",
    "# Part D: Analyze results and calculate performance metrics\n",
    "# Show decision distribution and compute precision/recall against ground truth\n",
    "\n",
    "# Show the distribution of final decisions\n",
    "print(\"\\nDecision counts →\", Counter(r[\"decision\"] for r in results))\n",
    "\n",
    "# Calculate precision and recall metrics\n",
    "# pred_set = all pairs our system classified as MATCH\n",
    "pred_set = {tuple(sorted((r[\"id1\"],r[\"id2\"]))) \n",
    "            for r in results if r[\"decision\"]==\"MATCH\"}\n",
    "\n",
    "# Calculate confusion matrix components\n",
    "tp = len(pred_set & gold_pairs)    # True Positives: correct MATCH predictions\n",
    "fp = len(pred_set - gold_pairs)    # False Positives: incorrect MATCH predictions  \n",
    "fn = len(gold_pairs - pred_set)    # False Negatives: missed MATCH pairs\n",
    "\n",
    "# Compute standard metrics\n",
    "precision = tp / (tp + fp) if tp + fp else 0.0  # Of predicted matches, how many were correct?\n",
    "recall    = tp / (tp + fn) if tp + fn else 0.0  # Of actual matches, how many did we find?\n",
    "print(f\"\\nPrecision {precision:0.2f}   |   Recall {recall:0.2f}\")\n",
    "\n",
    "# Part E: Inspect high-confidence predictions for quality analysis\n",
    "def fetch_pairs(dec: str, limit: int = 10, asc: bool = False):\n",
    "    \"\"\"Extract pairs with specific decision for manual inspection\"\"\"\n",
    "    rows = []\n",
    "    for r in results:\n",
    "        if r[\"decision\"] != dec:\n",
    "            continue\n",
    "        ctx = r.get(\"graph_ctx\")\n",
    "        # Skip pairs without proper context (shouldn't happen in normal cases)\n",
    "        if not ctx or \"products\" not in ctx or len(ctx[\"products\"]) < 2:\n",
    "            continue\n",
    "        p1, p2 = ctx[\"products\"]\n",
    "        rows.append({\n",
    "            \"id1\":   r[\"id1\"],\n",
    "            \"id2\":   r[\"id2\"],\n",
    "            \"title1\": p1.get(\"title_clean\", \"\"),\n",
    "            \"title2\": p2.get(\"title_clean\", \"\"),\n",
    "            \"prob\":  r[\"agentB_prob\"]  # Agent B's confidence score\n",
    "        })\n",
    "    # Sort by Agent B probability (high confidence first, or low if asc=True)\n",
    "    rows = sorted(rows, key=lambda d: d[\"prob\"], reverse=not asc)[:limit]\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "# Show examples of high-confidence decisions for manual verification\n",
    "print(\"\\nTop-10 MATCHes by Agent-B probability\")\n",
    "display(fetch_pairs(\"MATCH\"))\n",
    "\n",
    "print(\"\\nTop-10 NO_MATCHes by Agent-B probability\")\n",
    "display(fetch_pairs(\"NO_MATCH\", asc=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nodes now: 0\n"
     ]
    }
   ],
   "source": [
    "# in your notebook or script, before re‐ingesting:\n",
    "kb.query(\"MATCH (n) DETACH DELETE n\")\n",
    "print(\"Nodes now:\", kb.query(\"MATCH (n) RETURN count(n) AS c\")[0][\"c\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🧐 Reviewing 20 NEED_MORE_DATA pairs.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### 30841 vs 205554287\n",
       "```\n",
       "skagen premium steel slimline mesh womens watch 233xsgg\n",
       "vs\n",
       "233xsgg skagen\n",
       "```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### 32059 vs 205131849\n",
       "```\n",
       "unreal tournament iii video game for the sony ps3 unrealps3\n",
       "vs\n",
       "unreal tournament iii 26991\n",
       "```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "— recorded —\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### 35052 vs 210227260\n",
       "```json\n",
       "{ \"products\": [ { \"price\": 0.0, \"name\": \"Sharp 26' Black LCD HDTV With Built In DVD Player - LC26DV24U\", \"source\": \"abt\", \"title_clean\": \"sharp 26 black lcd hdtv with built in dvd player lc26dv24u\", \"brand_norm\": \"sharp\", \"prod_id\": \"35052\" }, { \"price\": 218.63, \"name\": \"Sharp AQUOS BD-HP21U Blu-ray Disc Player\", \"title_clean\": \"sharp aquos bd hp21u blu ray disc player\", \"source\": \"buy\", \"brand_norm\": \"sharp\", \"prod_id\": \"210227260\" } ], …\n",
       "```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "— recorded —\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### 38957 vs 207535265\n",
       "```\n",
       "lasonic atsc digital to analog tv converter box lta260\n",
       "vs\n",
       "lasonic lta 260 atsc converter box\n",
       "```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type y / n / s …\n",
      "— recorded —\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### 34282 vs 204793356\n",
       "```json\n",
       "{ \"products\": [ { \"price\": 0.0, \"name\": \"Sony Black Soft Carrying Case - LCSX30\", \"source\": \"abt\", \"title_clean\": \"sony black soft carrying case lcsx30\", \"brand_norm\": \"sony\", \"prod_id\": \"34282\" }, { \"price\": 0.0, \"name\": \"Sony SRS-BTM30 Wireless Stereo Bluetooth Speaker - SRSBTM30\", \"title_clean\": \"sony srs btm30 wireless stereo bluetooth speaker srsbtm30\", \"source\": \"buy\", \"brand_norm\": \"sony\", \"prod_id\": \"204793356\" } ], \"brands\": [ { …\n",
       "```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "— recorded —\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### 36084 vs 205664938\n",
       "```json\n",
       "{ \"products\": [ { \"price\": 18.0, \"name\": \"Canon Deluxe Burgundy Leather Case - 2350B001\", \"source\": \"abt\", \"title_clean\": \"canon deluxe burgundy leather case 2350b001\", \"brand_norm\": \"canon\", \"prod_id\": \"36084\" }, { \"price\": 16.97, \"name\": \"Canon PSC-1000 Semi-Hard Leather Case - 2350B001\", \"title_clean\": \"canon psc 1000 semi hard leather case 2350b001\", \"source\": \"buy\", \"brand_norm\": \"canon\", \"prod_id\": \"205664938\" } ], \"brands\": [ { \"name\": …\n",
       "```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "— recorded —\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### 30867 vs 205554724\n",
       "```\n",
       "seiko quartz le grand sport womens watch sxda04\n",
       "vs\n",
       "seiko sxda04\n",
       "```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### 25036 vs 202502745\n",
       "```\n",
       "lego star wars ii the original trilogy video game for the sony psp 023272329396\n",
       "vs\n",
       "lego star wars 2 the original trilogy\n",
       "```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "— recorded —\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### 38834 vs 209310268\n",
       "```\n",
       "nokia t mobile unlocked cellular phone n96\n",
       "vs\n",
       "nokia n96 unlocked phone 16gb 5mp camera with carl zeiss optics and dual led flash and auto focus built in gps wifi 002g6q3\n",
       "```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "— recorded —\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### 38480 vs 204647332\n",
       "```\n",
       "irobot robotic floor washer 74249\n",
       "vs\n",
       "irobot roomba scooba robot floor washer\n",
       "```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "— recorded —\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### 18441 vs 209002546\n",
       "```\n",
       "mosquito magnet defender replacement net mm4000net1\n",
       "vs\n",
       "mosquito magnet defender net replacement\n",
       "```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "— recorded —\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### 23296 vs 201647442\n",
       "```\n",
       "kingdom hearts ii video game for the sony ps2 662248904115\n",
       "vs\n",
       "kingdom hearts ii\n",
       "```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "— recorded —\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### 36722 vs 209656935\n",
       "```\n",
       "applecare protection plan for ipod touch or ipod classic mb591lla\n",
       "vs\n",
       "applecare for ipod touch or ipod classic mb591ll a\n",
       "```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "— recorded —\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### 38704 vs 209114575\n",
       "```\n",
       "vmware fusion 2 for mac vmfm20bx2\n",
       "vs\n",
       "vmware fusion 2 vmfm20bx2\n",
       "```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "— recorded —\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### 34016 vs 208042911\n",
       "```\n",
       "z line portland black tv stand zl2344mu\n",
       "vs\n",
       "z line designs zl23 44mu portland flat panel tv stand with integrated mount\n",
       "```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "— recorded —\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### 36083 vs 206362623\n",
       "```json\n",
       "{ \"products\": [ { \"price\": 0.0, \"name\": \"Canon Deluxe Grey Leather Case - 2349B001\", \"source\": \"abt\", \"title_clean\": \"canon deluxe grey leather case 2349b001\", \"brand_norm\": \"canon\", \"prod_id\": \"36083\" }, { \"price\": 19.99, \"name\": \"Canon PSC-1000 Semi-Hard Leather Case - 2349B001\", \"title_clean\": \"canon psc 1000 semi hard leather case 2349b001\", \"source\": \"buy\", \"brand_norm\": \"canon\", \"prod_id\": \"206362623\" } ], \"brands\": [ { \"name\": \"canon\" } …\n",
       "```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "— recorded —\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### 24825 vs 207388757\n",
       "```json\n",
       "{ \"products\": [ { \"price\": 119.0, \"name\": \"Panasonic Plain Paper Fax/Copier With Cordless Phone Answering System - Grey Finish - KXFG2451\", \"source\": \"abt\", \"title_clean\": \"panasonic plain paper fax copier with cordless phone answering system grey finish kxfg2451\", \"brand_norm\": \"panasonic\", \"prod_id\": \"24825\" }, { \"price\": 845.48, \"name\": \"Panasonic TH-42PZ80U - 42' Widescreen 1080p Plasma HDTV - 1,000,000:1 Dynamic Contrast Ratio\", \"source\": …\n",
       "```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "— recorded —\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### 24648 vs 203491687\n",
       "```\n",
       "waring professional cool touch deep fryer black stainless steel finish df100\n",
       "vs\n",
       "waring pro deep fryer 3qt black\n",
       "```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "— recorded —\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### 37421 vs 209896693\n",
       "```\n",
       "at t aliph jawbone ii silver bluetooth headset jawbone2s\n",
       "vs\n",
       "aliph jawbone 2 silver bluetooth headset retail 84442vrp\n",
       "```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "— recorded —\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### 31032 vs 210251970\n",
       "```\n",
       "chestnut hill sound george ipod music system in white chs4001\n",
       "vs\n",
       "chestnut hill chs40001 chestnut hill george ipod dock compact stereo system\n",
       "```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "— recorded —\n",
      "\n",
      "✅ Collected 18 human labels.\n",
      "📌 Labels saved to Neo4j as (:HumanLabel).\n"
     ]
    }
   ],
   "source": [
    "# Human-in-the-Loop: Manual labeling of uncertain cases             \n",
    "\n",
    "# When our AI agents are uncertain (NEED_MORE_DATA), get human expert input\n",
    "# This creates training data to improve future AI performance\n",
    "\n",
    "import json, textwrap, random, getpass\n",
    "from datetime import datetime\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "# Configuration for the human review process\n",
    "N_REVIEW    = 20    # How many uncertain pairs to review this session\n",
    "MAX_CHARS   = 450   # Truncate long JSON displays for readability\n",
    "RANDOM_SEED = 1     # Make the review order reproducible\n",
    "\n",
    "# Safety checks: ensure we have the required data and functions\n",
    "assert 'results' in globals(),          \"Run batch evaluation first!\"\n",
    "assert callable(get_product_subgraph),  \"Get_product_subgraph() missing!\"\n",
    "assert 'kb' in globals(),               \"Neo4j connection `kb` missing!\"\n",
    "assert 'df' in globals(),               \"Master DataFrame `df` missing!\"\n",
    "\n",
    "# Part A: Collect and prepare uncertain pairs for human review\n",
    "# Find all pairs where our AI system was uncertain and needs human guidance\n",
    "\n",
    "# Extract all NEED_MORE_DATA cases from our evaluation results\n",
    "# Get full context for each pair to help human reviewers make decisions\n",
    "need_pairs = [\n",
    "    (r[\"id1\"], r[\"id2\"], get_product_subgraph(r[\"id1\"], r[\"id2\"]))\n",
    "    for r in results if r[\"decision\"] == \"NEED_MORE_DATA\"\n",
    "]\n",
    "\n",
    "# Check if we have any uncertain cases to review\n",
    "if not need_pairs:\n",
    "    print(\"No NEED_MORE_DATA pairs to review.\")\n",
    "    raise SystemExit\n",
    "\n",
    "# Randomize order and select subset for this review session\n",
    "random.Random(RANDOM_SEED).shuffle(need_pairs)\n",
    "review_set = need_pairs[:N_REVIEW]\n",
    "print(f\"Reviewing {len(review_set)} NEED_MORE_DATA pairs.\\n\")\n",
    "\n",
    "labels = []  # Will collect human decisions for storage\n",
    "\n",
    "# Part B: Interactive human review process\n",
    "# Present each uncertain pair to human expert for manual classification\n",
    "\n",
    "for id1, id2, raw in review_set:\n",
    "    # Display product information for human review\n",
    "    if raw is not None:\n",
    "        # Show full Neo4j context (products, brands, neighbors, etc.)\n",
    "        ctx  = json.loads(raw)\n",
    "        blob = textwrap.shorten(\n",
    "            json.dumps(ctx, ensure_ascii=False, indent=2),\n",
    "            MAX_CHARS, placeholder=\" …\"\n",
    "        )\n",
    "        display(Markdown(f\"### {id1} vs {id2}\\n```json\\n{blob}\\n```\"))\n",
    "    else:\n",
    "        # Fallback: show just the cleaned product titles if no context available\n",
    "        titleA = df.loc[df.prod_id == id1, \"title_clean\"].iat[0]\n",
    "        titleB = df.loc[df.prod_id == id2, \"title_clean\"].iat[0]\n",
    "        display(Markdown(f\"### {id1} vs {id2}\\n```\\n{titleA}\\nvs\\n{titleB}\\n```\"))\n",
    "\n",
    "    # Get human decision with input validation\n",
    "    while True:\n",
    "        ans = input(\"[y] MATCH   [n] NO_MATCH   [s] skip → \").strip().lower()\n",
    "        if ans in {\"y\", \"n\", \"s\"}:\n",
    "            break\n",
    "        print(\"Type y / n / s …\")\n",
    "\n",
    "    # Skip this pair if human chooses to\n",
    "    if ans == \"s\":\n",
    "        continue\n",
    "\n",
    "    # Collect optional reasoning from human expert\n",
    "    reason = input(\"Optional short reason (press Enter to skip): \").strip() or \"(n/a)\"\n",
    "    \n",
    "    # Store the human decision with metadata\n",
    "    labels.append({\n",
    "        \"id1\":    id1,\n",
    "        \"id2\":    id2,\n",
    "        \"label\":  \"MATCH\"     if ans == \"y\" else \"NO_MATCH\",\n",
    "        \"reason\": reason,\n",
    "        \"user\":   getpass.getuser(),  # Track who made the decision\n",
    "        \"ts\":     datetime.utcnow().isoformat(),  # When it was made\n",
    "    })\n",
    "    print(\"— recorded —\\n\")\n",
    "\n",
    "print(f\"Collected {len(labels)} human labels.\")\n",
    "\n",
    "# Part C: Store human labels in Neo4j for future use\n",
    "# Save expert decisions as training data for improving AI performance\n",
    "\n",
    "if labels:\n",
    "    # Store human labels as HumanLabel nodes in Neo4j\n",
    "    kb.query(\"\"\"\n",
    "    UNWIND $rows AS row\n",
    "    MERGE (h:HumanLabel {id1:row.id1, id2:row.id2})\n",
    "      SET h.label  = row.label,\n",
    "          h.reason = row.reason,\n",
    "          h.user   = row.user,\n",
    "          h.ts     = row.ts\n",
    "    \"\"\", params={\"rows\": labels})\n",
    "    print(\"Labels saved to Neo4j as (:HumanLabel).\")\n",
    "else:\n",
    "    print(\"Nothing saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Part D: Update Resolution decisions with human labels\n",
    "# Override AI decisions with human expert judgments for better accuracy\n",
    "\n",
    "# Retrieve all human labels from Neo4j\n",
    "hl_rows = kb.query(\"MATCH (h:HumanLabel) RETURN h.id1 AS id1, h.id2 AS id2, h.label AS label\")\n",
    "\n",
    "# Update existing Resolution nodes to use human decisions instead of AI decisions\n",
    "kb.query(\"\"\"\n",
    "UNWIND $rows AS row\n",
    "MATCH (r:Resolution {id1:row.id1, id2:row.id2})\n",
    "SET r.decision = row.label\n",
    "\"\"\", params={ \"rows\": hl_rows })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated decision counts → {'NO_MATCH': 521, 'MATCH': 1065, 'NEED_MORE_DATA': 6}\n"
     ]
    }
   ],
   "source": [
    "# Part E: Show updated decision distribution after human input\n",
    "# Display how human labels changed the overall decision statistics\n",
    "\n",
    "res_counts = kb.query(\"\"\"\n",
    "MATCH (r:Resolution)\n",
    "OPTIONAL MATCH (h:HumanLabel)\n",
    "  WHERE (h.id1 = r.id1 AND h.id2 = r.id2)\n",
    "     OR (h.id1 = r.id2 AND h.id2 = r.id1)\n",
    "WITH coalesce(h.label, r.decision) AS finalDecision, count(*) AS cnt\n",
    "RETURN finalDecision AS decision, cnt\n",
    "\"\"\")\n",
    "\n",
    "# Convert to dictionary and display the updated distribution\n",
    "counts = {rec[\"decision\"]: rec[\"cnt\"] for rec in res_counts}\n",
    "print(\"Updated decision counts →\", counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id1</th>\n",
       "      <th>name1</th>\n",
       "      <th>id2</th>\n",
       "      <th>name2</th>\n",
       "      <th>decision</th>\n",
       "      <th>agentA</th>\n",
       "      <th>reason</th>\n",
       "      <th>prob</th>\n",
       "      <th>ts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10333368</td>\n",
       "      <td>Kensington Orbit Optical Trackball - USB w/PS2...</td>\n",
       "      <td>34309</td>\n",
       "      <td>Sony Bravia Wireless Home Theater System In Bl...</td>\n",
       "      <td>NO_MATCH</td>\n",
       "      <td>NO</td>\n",
       "      <td>brands differ</td>\n",
       "      <td>0.05</td>\n",
       "      <td>2025-06-11T15:17:58.528076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>203341506</td>\n",
       "      <td>Olympus Slim Leather Case - 202087</td>\n",
       "      <td>25732</td>\n",
       "      <td>Olympus Premium Slim Leather Case In Black - 2...</td>\n",
       "      <td>MATCH</td>\n",
       "      <td>YES</td>\n",
       "      <td>identical brand and very similar titles</td>\n",
       "      <td>0.95</td>\n",
       "      <td>2025-06-11T15:18:48.265649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>16329</td>\n",
       "      <td>Whirlpool 24' Built-In Dishwasher - DU1100SS</td>\n",
       "      <td>210521578</td>\n",
       "      <td>Whirlpool DU1100XTPS 24' Undercounter Dishwash...</td>\n",
       "      <td>MATCH</td>\n",
       "      <td>UNSURE</td>\n",
       "      <td>similar titles but price gap &gt; 30%</td>\n",
       "      <td>0.85</td>\n",
       "      <td>2025-06-11T15:18:48.504967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>209114552</td>\n",
       "      <td>Canon PowerShot A1000 IS Digital Camera - Gray...</td>\n",
       "      <td>37123</td>\n",
       "      <td>Canon PowerShot A1000 IS Gray Digital Camera -...</td>\n",
       "      <td>MATCH</td>\n",
       "      <td>YES</td>\n",
       "      <td>identical brand and very similar titles</td>\n",
       "      <td>0.95</td>\n",
       "      <td>2025-06-11T15:18:48.534120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>202973389</td>\n",
       "      <td>Techcraft Veneto Series ABS32 TV Stand</td>\n",
       "      <td>25813</td>\n",
       "      <td>Tech Craft Avalon Series TV Stand - Black Fini...</td>\n",
       "      <td>MATCH</td>\n",
       "      <td>UNSURE</td>\n",
       "      <td>different brands, similar titles, price gap ex...</td>\n",
       "      <td>0.85</td>\n",
       "      <td>2025-06-11T15:18:48.713573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>205753566</td>\n",
       "      <td>Speck Products ToughSkin for iPod classic - IC...</td>\n",
       "      <td>31392</td>\n",
       "      <td>Speck Black ToughSkin iPod Classic Case - ICBLKTS</td>\n",
       "      <td>MATCH</td>\n",
       "      <td>YES</td>\n",
       "      <td>identical brand and very similar titles</td>\n",
       "      <td>0.95</td>\n",
       "      <td>2025-06-11T15:18:50.349899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>205664913</td>\n",
       "      <td>GE 24775 Amplified Quantum HDTV Antenna</td>\n",
       "      <td>32416</td>\n",
       "      <td>GE Amplified Quantum Antenna - TV24775</td>\n",
       "      <td>MATCH</td>\n",
       "      <td>YES</td>\n",
       "      <td>identical brand and very similar titles</td>\n",
       "      <td>0.95</td>\n",
       "      <td>2025-06-11T15:18:50.442213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>206808434</td>\n",
       "      <td>Canon VIXIA HF10 High Definition Digital Camco...</td>\n",
       "      <td>33280</td>\n",
       "      <td>Canon Vixia High Definition Camcorder - HF10</td>\n",
       "      <td>MATCH</td>\n",
       "      <td>YES</td>\n",
       "      <td>identical title+brand</td>\n",
       "      <td>0.95</td>\n",
       "      <td>2025-06-11T15:18:50.460754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>23350</td>\n",
       "      <td>Sony PlayStation 2 8MB Memory Card (2 Pack) - ...</td>\n",
       "      <td>50012447</td>\n",
       "      <td>SONY 7-11719-70670-0 PS2 8 MB Memory Card 2-pk...</td>\n",
       "      <td>MATCH</td>\n",
       "      <td>YES</td>\n",
       "      <td>identical title+brand</td>\n",
       "      <td>0.95</td>\n",
       "      <td>2025-06-11T15:18:50.479788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>202486964</td>\n",
       "      <td>GE Millennium TV Antenna - 24734</td>\n",
       "      <td>21182</td>\n",
       "      <td>GE Platinum HDTV Millennium TV Antenna - TV24734</td>\n",
       "      <td>MATCH</td>\n",
       "      <td>YES</td>\n",
       "      <td>identical brand and very similar titles</td>\n",
       "      <td>0.95</td>\n",
       "      <td>2025-06-11T15:18:52.122651</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id1                                              name1        id2  \\\n",
       "0   10333368  Kensington Orbit Optical Trackball - USB w/PS2...      34309   \n",
       "1  203341506                 Olympus Slim Leather Case - 202087      25732   \n",
       "2      16329       Whirlpool 24' Built-In Dishwasher - DU1100SS  210521578   \n",
       "3  209114552  Canon PowerShot A1000 IS Digital Camera - Gray...      37123   \n",
       "4  202973389             Techcraft Veneto Series ABS32 TV Stand      25813   \n",
       "5  205753566  Speck Products ToughSkin for iPod classic - IC...      31392   \n",
       "6  205664913            GE 24775 Amplified Quantum HDTV Antenna      32416   \n",
       "7  206808434  Canon VIXIA HF10 High Definition Digital Camco...      33280   \n",
       "8      23350  Sony PlayStation 2 8MB Memory Card (2 Pack) - ...   50012447   \n",
       "9  202486964                   GE Millennium TV Antenna - 24734      21182   \n",
       "\n",
       "                                               name2  decision  agentA  \\\n",
       "0  Sony Bravia Wireless Home Theater System In Bl...  NO_MATCH      NO   \n",
       "1  Olympus Premium Slim Leather Case In Black - 2...     MATCH     YES   \n",
       "2  Whirlpool DU1100XTPS 24' Undercounter Dishwash...     MATCH  UNSURE   \n",
       "3  Canon PowerShot A1000 IS Gray Digital Camera -...     MATCH     YES   \n",
       "4  Tech Craft Avalon Series TV Stand - Black Fini...     MATCH  UNSURE   \n",
       "5  Speck Black ToughSkin iPod Classic Case - ICBLKTS     MATCH     YES   \n",
       "6             GE Amplified Quantum Antenna - TV24775     MATCH     YES   \n",
       "7       Canon Vixia High Definition Camcorder - HF10     MATCH     YES   \n",
       "8  SONY 7-11719-70670-0 PS2 8 MB Memory Card 2-pk...     MATCH     YES   \n",
       "9   GE Platinum HDTV Millennium TV Antenna - TV24734     MATCH     YES   \n",
       "\n",
       "                                              reason  prob  \\\n",
       "0                                      brands differ  0.05   \n",
       "1            identical brand and very similar titles  0.95   \n",
       "2                 similar titles but price gap > 30%  0.85   \n",
       "3            identical brand and very similar titles  0.95   \n",
       "4  different brands, similar titles, price gap ex...  0.85   \n",
       "5            identical brand and very similar titles  0.95   \n",
       "6            identical brand and very similar titles  0.95   \n",
       "7                              identical title+brand  0.95   \n",
       "8                              identical title+brand  0.95   \n",
       "9            identical brand and very similar titles  0.95   \n",
       "\n",
       "                           ts  \n",
       "0  2025-06-11T15:17:58.528076  \n",
       "1  2025-06-11T15:18:48.265649  \n",
       "2  2025-06-11T15:18:48.504967  \n",
       "3  2025-06-11T15:18:48.534120  \n",
       "4  2025-06-11T15:18:48.713573  \n",
       "5  2025-06-11T15:18:50.349899  \n",
       "6  2025-06-11T15:18:50.442213  \n",
       "7  2025-06-11T15:18:50.460754  \n",
       "8  2025-06-11T15:18:50.479788  \n",
       "9  2025-06-11T15:18:52.122651  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅  Saved full table with names to stress_resolutions_with_names.csv\n"
     ]
    }
   ],
   "source": [
    "# Export Results: Create comprehensive reports for analysis          \n",
    "# Export resolution data with product names for easy review and presentation\n",
    "import pandas as pd\n",
    "\n",
    "# Part A: Basic resolution export with product names\n",
    "# Pull all resolution data with readable product names for manual inspection\n",
    "\n",
    "rows = kb.query(\"\"\"\n",
    "MATCH (r:Resolution)\n",
    "MATCH (p1:Product {prod_id: r.id1})\n",
    "MATCH (p2:Product {prod_id: r.id2})\n",
    "RETURN\n",
    "  r.id1        AS id1,\n",
    "  p1.name      AS name1,\n",
    "  r.id2        AS id2,\n",
    "  p2.name      AS name2,\n",
    "  r.decision   AS decision,\n",
    "  r.agentA     AS agentA,\n",
    "  r.reason     AS reason,\n",
    "  r.prob       AS prob,\n",
    "  r.ts         AS ts\n",
    "\"\"\")\n",
    "\n",
    "# Convert to DataFrame for easy manipulation and viewing\n",
    "df_res = pd.DataFrame(rows)\n",
    "display(df_res.head(10))\n",
    "\n",
    "# Export to CSV for external analysis (Excel, presentations, etc.)\n",
    "csv_path = \"stress_resolutions_with_names.csv\"\n",
    "df_res.to_csv(csv_path, index=False)\n",
    "print(f\"✅  Saved full table with names to {csv_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Wrote 1,592 rows to resolutions_with_reasons.csv\n"
     ]
    }
   ],
   "source": [
    "# Part B: Comprehensive export with human overrides and reasoning\n",
    "# Create a detailed report that prioritizes human decisions over AI decisions\n",
    "\n",
    "rows = kb.query(\"\"\"\n",
    "MATCH (r:Resolution)\n",
    "OPTIONAL MATCH (h:HumanLabel)\n",
    "  WHERE (h.id1 = r.id1 AND h.id2 = r.id2)\n",
    "     OR (h.id1 = r.id2 AND h.id2 = r.id1)\n",
    "WITH r, h,\n",
    "     coalesce(h.label, r.decision) AS finalDecision,\n",
    "     coalesce(h.reason, r.reason) AS finalReason\n",
    "\n",
    "// Get readable product names for both products in each pair\n",
    "MATCH (a:Product {prod_id: r.id1})\n",
    "MATCH (b:Product {prod_id: r.id2})\n",
    "\n",
    "RETURN\n",
    "  r.id1           AS ProductA_id,\n",
    "  a.name          AS ProductA_name,\n",
    "  r.id2           AS ProductB_id,\n",
    "  b.name          AS ProductB_name,\n",
    "  r.agentA        AS AgentA_lbl,\n",
    "  r.prob          AS AgentB_prob,\n",
    "  finalDecision   AS FinalDecision,\n",
    "  finalReason     AS Reason\n",
    "\"\"\")\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Create final results DataFrame with human-prioritized decisions\n",
    "df = pd.DataFrame(rows)\n",
    "df.to_csv(\"stress_resolutions_with_reasons.csv\", index=False)\n",
    "print(f\"✅ Wrote {len(df):,} rows to resolutions_with_reasons.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "entity_res",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
